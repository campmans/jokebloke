{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ebe9f644",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import wave\n",
    "import speech_recognition as sr\n",
    "from io import BytesIO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afaacb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import wave\n",
    "import speech_recognition as sr\n",
    "from io import BytesIO\n",
    "import pyttsx3\n",
    "\n",
    "# ----------------------------\n",
    "# Convert recorder audio to WAV in-memory\n",
    "# ----------------------------\n",
    "def get_audio_as_wav_bytes(recorder):\n",
    "    \"\"\"Return recorder audio as a WAV byte stream.\"\"\"\n",
    "    data = recorder.audiodata\n",
    "    srate = recorder.sampleRate\n",
    "    \n",
    "    if data is None or len(data) == 0:\n",
    "        raise ValueError(\"No audio recorded!\")\n",
    "\n",
    "    # Convert float32 [-1,1] → int16\n",
    "    data_int16 = (data * 32767).astype(np.int16)\n",
    "\n",
    "    # Write WAV to BytesIO\n",
    "    wav_bytes = BytesIO()\n",
    "    with wave.open(wav_bytes, 'wb') as wf:\n",
    "        wf.setnchannels(1)\n",
    "        wf.setsampwidth(2)\n",
    "        wf.setframerate(srate)\n",
    "        wf.writeframes(data_int16.tobytes())\n",
    "    wav_bytes.seek(0)\n",
    "    return wav_bytes\n",
    "\n",
    "# ----------------------------\n",
    "# Transcribe using speech_recognition\n",
    "# ----------------------------\n",
    "def transcribe(recorder):\n",
    "    wav_bytes = get_audio_as_wav_bytes(recorder)\n",
    "    \n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(wav_bytes) as source:\n",
    "        audio = recognizer.record(source)\n",
    "    \n",
    "    # You can use different recognizers, here we use Google free API\n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio)\n",
    "        print(\"Transcription:\", text)\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Could not understand audio\")\n",
    "        return \"\"\n",
    "    except sr.RequestError as e:\n",
    "        print(f\"API error: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "#Text to speech\n",
    "def SpeakText(command):\n",
    "    \n",
    "    # Initialize the engine\n",
    "    engine = pyttsx3.init()\n",
    "    engine.say(command) \n",
    "    engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499d270d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Plot and Save audio (optional)\n",
    "def save_wav_from_recorder(recorder, filename=\"recording.wav\"):\n",
    "    \"\"\"Save the recorded audio from recorder into a WAV file.\"\"\"\n",
    "    data = recorder.audiodata\n",
    "    sr = recorder.sampleRate\n",
    "    \n",
    "    if data is None or len(data) == 0:\n",
    "        print(\"No audio data to save!\")\n",
    "        return None\n",
    "\n",
    "    # Convert float32 [-1,1] → int16\n",
    "    data_int16 = (data * 32767).astype(np.int16)\n",
    "\n",
    "    with wave.open(filename, \"wb\") as f:\n",
    "        f.setnchannels(1)\n",
    "        f.setsampwidth(2)  # int16\n",
    "        f.setframerate(sr)\n",
    "        f.writeframes(data_int16.tobytes())\n",
    "\n",
    "    print(f\"Saved: {filename}\")\n",
    "    return filename\n",
    "\n",
    "def plot_audio(rec):        \n",
    "    # Plot waveform\n",
    "    plt.figure(figsize=(10,3))\n",
    "    plt.plot(rec.audiodata)\n",
    "    plt.title(\"Recorded Audio Waveform\")\n",
    "    plt.xlabel(\"Samples\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65218f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62c46398945f444d9fc699d2f1010d0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "AudioRecorder()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "590707993f3444c98cd73303682ae38c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border_bottom='1px solid black', border_left='1px solid black', border_right='1px solid b…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Audio Recorder Notebook\n",
    "# ----------------------------\n",
    "\n",
    "import numpy as np\n",
    "import wave\n",
    "import ipyaudioworklet as ipyaudio\n",
    "from ipywidgets import Output, VBox\n",
    "from IPython.display import display\n",
    "\n",
    "# ----------------------------\n",
    "# Create Recorder\n",
    "# ----------------------------\n",
    "rec = ipyaudio.AudioRecorder()\n",
    "display(rec)\n",
    "\n",
    "# ----------------------------\n",
    "# Status Output\n",
    "# ----------------------------\n",
    "status_out = Output(layout={'border': '1px solid black', 'padding': '5px'})\n",
    "status_out.append_stdout(\"Recorder ready.\\n\")\n",
    "display(status_out)\n",
    "\n",
    "@status_out.capture(clear_output=True)\n",
    "def status_changed(change):\n",
    "    print(\"Status:\", change.new)\n",
    "\n",
    "rec.observe(status_changed, \"status\")\n",
    "\n",
    "# ----------------------------\n",
    "# Automatic Save and Plot\n",
    "# ----------------------------\n",
    "@status_out.capture()\n",
    "def on_status_change(change):\n",
    "    if change.new in (\"STOPPED\", \"RECORDED\"):\n",
    "        \n",
    "        text = transcribe(rec)\n",
    "        \n",
    "        SpeakText(text)\n",
    "        \n",
    "        #fname = save_wav_from_recorder(rec)\n",
    "        #Plot(rec)\n",
    "        \n",
    "\n",
    "rec.observe(on_status_change, \"status\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab917312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Persona:** You are an observational comedian who finds the absurd in the mundane. Your humor comes from dissecting everyday situations, social etiquette, and common frustrations that everyone experiences but no one talks about. You judge joke quality by **relatability** and **insightfulness**.\n",
      "\n",
      " **Task:**\n",
      "1.  Analyze the user's input to identify the core topic.\n",
      "2.  Generate 5 jokes related to that topic.\n",
      "3.  Rank them from best (sharpest and most relevant) to worst.\n",
      "4.  Respond ONLY with the specified XML output. Do not include any conversational text or explanations.\n",
      "\n",
      "**Output Format:**\n",
      "A ranked list of jokes in XML. The score is your rating of the joke's quality from 1 to 5.\n",
      "\n",
      "<jokes>\n",
      "  <joke score=\"[score]\">[JOKE]</joke>\n",
      "  <joke score=\"[score]\">[JOKE]</joke>\n",
      "  <joke score=\"[score]\">[JOKE]</joke>\n",
      "</jokes>\n",
      "Response:\n",
      " <jokes>\n",
      "  <joke score=\"5\">My therapist told me I need to live in the moment. I said, 'Which moment? The one where that guy held the door for me, but then we both walked the same direction, creating an awkward power-walk competition? Because *that's* material, Brenda.'</joke>\n",
      "  <joke score=\"5\">The purest form of observational comedy is the moment you realize everyone else is also just as confused by the self-checkout machine, but we all collectively pretend we're experts. It's the silent ballet of barcode scanning failure.</joke>\n",
      "  <joke score=\"4\">The best part of observational comedy is seeing that little nod of recognition in the audience. It's like we've all been members of a secret society of shared, minor annoyances, and I'm just the one brave enough to shout our sacred truths.</joke>\n",
      "  <joke score=\"3\">Being an observational comedian means never truly experiencing a moment, only dissecting it for future comedic potential. My brain's constantly filing things under 'That's a bit much' or 'Why do we do that?'</joke>\n",
      "  <joke score=\"3\">People always ask what I talk about. I say, 'Everything you just did wrong, but didn't realize.' Then they get awkward. It's the best part of my job.</joke>\n",
      "</jokes>\n",
      "Summary:\n",
      " The previous prompt and conversation revolved around an AI persona acting as an observational comedian, generating jokes about the nature of observational comedy itself and common social awkwardness.\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "path = os.getcwd()\n",
    "profiles = [file for file in os.listdir(os.path.join(path, \"prompts\")) if \"output\" not in file]\n",
    "output_format = \"prompts/output-format.md\"\n",
    "random_profile = np.random.choice(profiles)\n",
    "\n",
    "# Importing random prompt profile\n",
    "with open(f'prompts/{random_profile}', 'r') as f:\n",
    "    profile = f.read()\n",
    "\n",
    "# Importing output format\n",
    "with open(f'{output_format}', 'r') as f:\n",
    "    output = f.read()\n",
    "\n",
    "profile = profile + \"\\n \" + output\n",
    "print(profile)\n",
    "\n",
    "summary = f\"{profile}\"  # previous prompts summary\n",
    "\n",
    "\n",
    "def generate_response(user_response=\"\"):\n",
    "    global summary\n",
    "    global profile\n",
    "\n",
    "    # Gemini api key [Aby]\n",
    "    client = genai.Client(api_key=\"AIzaSyDUFGVRem15WWKpvXxOiXmnQutlUrMZZvc\")\n",
    "\n",
    "    # Prompting LLM to respond tell a joke\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        config=types.GenerateContentConfig(\n",
    "            system_instruction=f\"{profile}\"),\n",
    "        contents=f\"{user_response}\",\n",
    "    )\n",
    "    model_response = response.text\n",
    "    print(\"Response:\\n\",response.text)\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        config=types.GenerateContentConfig(\n",
    "            system_instruction=f\"\"\"\n",
    "            Generate a very brief summary of the topic of the previous prompt and conversation: \n",
    "            **Prompt**\n",
    "            {summary}\n",
    "            **Conversation**\n",
    "            {model_response} \n",
    "            \"\"\"),\n",
    "        contents=f\"{user_response}\",\n",
    "    )\n",
    "    summary = response.text\n",
    "    print(\"Summary:\\n\", summary)\n",
    "\n",
    "generate_response(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jokebloke",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
