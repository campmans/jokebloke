{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebe9f644",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# JokeBloke: Interactive Voice-Controlled Comedy Assistant\n",
    "# ============================================================================\n",
    "# This notebook implements an AI-powered joke generation system with:\n",
    "# - Voice input/output for natural conversation\n",
    "# - Multiple comedy personality profiles\n",
    "# - Contextual memory tracking\n",
    "# - User feedback learning (UCB algorithm)\n",
    "# ============================================================================\n",
    "\n",
    "# Suppress deprecation warnings from pygame and pkg_resources\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, message='.*pkg_resources.*')\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning, module='pygame')\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='pygame.pkgdata')\n",
    "\n",
    "# Standard Library Imports\n",
    "import os\n",
    "import random\n",
    "import threading\n",
    "import wave\n",
    "import subprocess\n",
    "import xml.etree.ElementTree as ET\n",
    "from abc import ABC, abstractmethod\n",
    "from collections import defaultdict\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "from typing import Literal\n",
    "import tempfile\n",
    "\n",
    "# Jupyter and Widget Libraries\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Output\n",
    "import ipyaudioworklet as ipyaudio\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Data Science and Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Audio and Speech Processing\n",
    "from gtts import gTTS  # Text-to-speech\n",
    "\n",
    "# Suppress pygame import warnings with context manager\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", UserWarning)\n",
    "    import pygame  # Audio playback\n",
    "\n",
    "import speech_recognition as sr  # Speech-to-text\n",
    "\n",
    "# Natural Language Processing\n",
    "import spacy  # For linguistic feature extraction\n",
    "\n",
    "# Google Gemini API\n",
    "from google import genai\n",
    "from google.genai import types\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47657ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Multi-Language Configuration\n",
    "# ============================================================================\n",
    "# JokeBloke ondersteunt meerdere talen / JokeBloke supports multiple languages\n",
    "# Beschikbare talen / Available languages: 'nl' (Nederlands), 'de' (Deutsch)\n",
    "# ============================================================================\n",
    "\n",
    "# Configureer de gewenste taal hier / Configure desired language here\n",
    "LANGUAGE = 'en-gb'  # Opties / Optionen / Options / Opzioni: 'nl', 'de', 'en-gb', 'it'\n",
    "\n",
    "# Taalconfiguratie / Language configuration\n",
    "LANGUAGE_CONFIG = {\n",
    "    'nl': {\n",
    "        'name': 'Nederlands',\n",
    "        'spacy_model': 'nl_core_news_sm',\n",
    "        'speech_recognition': 'nl-NL',\n",
    "        'tts_lang': 'nl',\n",
    "        'ui': {\n",
    "            'title': 'JokeBloke',\n",
    "            'instruction': 'Druk op `boot recorder` om hem wakker te maken. Druk vervolgens op `record` om tegen hem te praten. Als je klaar bent met praten, druk dan op `stop` en wacht geduldig op zijn reactie.',\n",
    "            'like_question': 'Vind je dit leuk?',\n",
    "            'loading': 'Bedenk iets grappigs...',\n",
    "            'recorder_ready': 'Recorder klaar.\\n',\n",
    "            'transcription': 'Transcriptie:',\n",
    "            'could_not_understand': 'Kon audio niet verstaan',\n",
    "            'api_error': 'API fout:',\n",
    "            'personality': 'Persoonlijkheid:',\n",
    "            'response': 'Reactie:',\n",
    "            'thanks': 'Dank je!',\n",
    "            'you_liked': 'Je vond dit leuk!',\n",
    "            'tough_crowd': 'Wow, lastig publiek!',\n",
    "            'you_disliked': 'Je vond dit niet leuk!',\n",
    "        },\n",
    "        'loading_messages': [\n",
    "            \"Even geduld, ik werk eraan...\",\n",
    "            \"Komedie kost tijd, anders dan het geduld van mijn ex...\",\n",
    "            \"Nog aan het denken... in tegenstelling tot mijn comedycarri\u00e8re gaat dit ergens heen\",\n",
    "            \"Een momentje, genie aan het werk... of op z'n minst lichte entertainment\",\n",
    "            \"Humor aan het laden... even geduld alstublieft\",\n",
    "            \"Mijn schrijvers staken weer...\",\n",
    "            \"Buffer humor... heb je geprobeerd me uit en aan te zetten?\",\n",
    "            \"Raadpleeg mijn innerlijke clown...\",\n",
    "            \"De clou zit vast in het verkeer...\",\n",
    "            \"Bijna klaar... comedy goud groeit niet op bomen\",\n",
    "            \"Even volhouden, ik ben grappiger dan deze pauze doet vermoeden\",\n",
    "            \"Bezig met verwerken... deze grap kan maar beter goed zijn\",\n",
    "            \"Mijn humorbot heeft even nodig...\",\n",
    "            \"Grap aan het laden... in tegenstelling tot mijn liefdeleven komt dit wel af\",\n",
    "            \"Ik stel niet uit, ik bouw spanning op...\",\n",
    "            \"Rome is niet in \u00e9\u00e9n dag gebouwd, comedy goud ook niet\",\n",
    "        ]\n",
    "    },\n",
    "    'de': {\n",
    "        'name': 'Deutsch',\n",
    "        'spacy_model': 'de_core_news_sm',\n",
    "        'speech_recognition': 'de-DE',\n",
    "        'tts_lang': 'de',\n",
    "        'ui': {\n",
    "            'title': 'JokeBloke',\n",
    "            'instruction': 'Dr\u00fccken Sie `boot recorder`, um ihn aufzuwecken. Dr\u00fccken Sie dann `record`, um mit ihm zu sprechen. Wenn Sie fertig sind, dr\u00fccken Sie `stop` und warten Sie geduldig auf seine Antwort.',\n",
    "            'like_question': 'Gef\u00e4llt dir das?',\n",
    "            'loading': 'Denke mir etwas Lustiges aus...',\n",
    "            'recorder_ready': 'Recorder bereit.\\n',\n",
    "            'transcription': 'Transkription:',\n",
    "            'could_not_understand': 'Konnte Audio nicht verstehen',\n",
    "            'api_error': 'API-Fehler:',\n",
    "            'personality': 'Pers\u00f6nlichkeit:',\n",
    "            'response': 'Antwort:',\n",
    "            'thanks': 'Danke!',\n",
    "            'you_liked': 'Das gefiel dir!',\n",
    "            'tough_crowd': 'Wow, hartes Publikum!',\n",
    "            'you_disliked': 'Das gefiel dir nicht!',\n",
    "        },\n",
    "        'loading_messages': [\n",
    "            \"Einen Moment, ich arbeite daran...\",\n",
    "            \"Comedy braucht Zeit, im Gegensatz zur Geduld meiner Ex...\",\n",
    "            \"Denke noch nach... im Gegensatz zu meiner Comedy-Karriere f\u00fchrt das irgendwohin\",\n",
    "            \"Einen Augenblick, Genie bei der Arbeit... oder zumindest leichte Unterhaltung\",\n",
    "            \"Humor wird geladen... bitte warten\",\n",
    "            \"Meine Autoren streiken wieder...\",\n",
    "            \"Buffere Humor... haben Sie versucht, mich aus- und wieder einzuschalten?\",\n",
    "            \"Konsultiere meinen inneren Clown...\",\n",
    "            \"Die Pointe steckt im Verkehr fest...\",\n",
    "            \"Fast fertig... Comedy-Gold gr\u00e4bt sich nicht selbst\",\n",
    "            \"Halten Sie durch, ich bin lustiger als diese Pause vermuten l\u00e4sst\",\n",
    "            \"Verarbeite... dieser Witz sollte besser gut sein\",\n",
    "            \"Mein Humormodul braucht einen Moment...\",\n",
    "            \"Witz wird geladen... im Gegensatz zu meinem Liebesleben wird das fertig\",\n",
    "            \"Ich z\u00f6gere nicht, ich baue Spannung auf...\",\n",
    "            \"Rom wurde nicht an einem Tag erbaut, Comedy-Gold auch nicht\",\n",
    "        ]\n",
    "    }\n",
    "    ,\n",
    "    'en-gb': {\n",
    "        'name': 'English (UK)',\n",
    "        'spacy_model': 'en_core_web_sm',\n",
    "        'speech_recognition': 'en-GB',\n",
    "        'tts_lang': 'en',\n",
    "        'tts_tld': 'co.uk',  # British accent\n",
    "        'ui': {\n",
    "            'title': 'JokeBloke',\n",
    "            'instruction': 'Press `boot recorder` to wake him up. Then press `record` to talk to him. When you\\'re done talking, press `stop` and wait patiently for his response.',\n",
    "            'like_question': 'Do you like this?',\n",
    "            'loading': 'Thinking of something funny...',\n",
    "            'recorder_ready': 'Recorder ready.\\n',\n",
    "            'transcription': 'Transcription:',\n",
    "            'could_not_understand': 'Could not understand audio',\n",
    "            'api_error': 'API error:',\n",
    "            'personality': 'Personality:',\n",
    "            'response': 'Response:',\n",
    "            'thanks': 'Cheers!',\n",
    "            'you_liked': 'You liked this!',\n",
    "            'tough_crowd': 'Blimey, tough crowd!',\n",
    "            'you_disliked': 'You disliked this!',\n",
    "        },\n",
    "        'loading_messages': [\n",
    "            \"Hold on, I'm working on it...\",\n",
    "            \"Comedy takes time, unlike my ex's patience...\",\n",
    "            \"Still thinking... unlike my comedy career, this is going somewhere\",\n",
    "            \"One moment, genius at work... or at least mild amusement\",\n",
    "            \"Loading wit... please stand by\",\n",
    "            \"My writers are on strike again...\",\n",
    "            \"Buffering humour... have you tried turning me off and on again?\",\n",
    "            \"Consulting my inner clown...\",\n",
    "            \"The punchline is stuck in traffic...\",\n",
    "            \"Almost there... comedy gold doesn't mine itself\",\n",
    "            \"Hang tight, I'm funnier than this pause suggests\",\n",
    "            \"Processing... this joke better be worth it\",\n",
    "            \"My funny bone needs a moment...\",\n",
    "            \"Joke loading... unlike my love life, this will complete\",\n",
    "            \"I'm not stalling, I'm building suspense...\",\n",
    "            \"Rome wasn't built in a day, and neither is comedy gold\",\n",
    "        ]\n",
    "    },\n",
    "    'it': {\n",
    "        'name': 'Italiano',\n",
    "        'spacy_model': 'it_core_news_sm',\n",
    "        'speech_recognition': 'it-IT',\n",
    "        'tts_lang': 'it',\n",
    "        'ui': {\n",
    "            'title': 'JokeBloke',\n",
    "            'instruction': 'Premi `boot recorder` per svegliarlo. Poi premi `record` per parlargli. Quando hai finito di parlare, premi `stop` e aspetta pazientemente la sua risposta.',\n",
    "            'like_question': 'Ti piace?',\n",
    "            'loading': 'Sto pensando qualcosa di divertente...',\n",
    "            'recorder_ready': 'Registratore pronto.\\n',\n",
    "            'transcription': 'Trascrizione:',\n",
    "            'could_not_understand': 'Impossibile comprendere l\\'audio',\n",
    "            'api_error': 'Errore API:',\n",
    "            'personality': 'Personalit\u00e0:',\n",
    "            'response': 'Risposta:',\n",
    "            'thanks': 'Grazie!',\n",
    "            'you_liked': 'Ti \u00e8 piaciuto!',\n",
    "            'tough_crowd': 'Mamma mia, che pubblico difficile!',\n",
    "            'you_disliked': 'Non ti \u00e8 piaciuto!',\n",
    "        },\n",
    "        'loading_messages': [\n",
    "            \"Aspetta, ci sto lavorando...\",\n",
    "            \"La commedia richiede tempo, a differenza della pazienza della mia ex...\",\n",
    "            \"Sto ancora pensando... a differenza della mia carriera comica, questo porter\u00e0 da qualche parte\",\n",
    "            \"Un momento, genio al lavoro... o almeno divertimento leggero\",\n",
    "            \"Caricamento umorismo... attendere prego\",\n",
    "            \"I miei autori sono di nuovo in sciopero...\",\n",
    "            \"Buffering comicit\u00e0... hai provato a spegnermi e riaccendermi?\",\n",
    "            \"Consulto il mio clown interiore...\",\n",
    "            \"La battuta finale \u00e8 bloccata nel traffico...\",\n",
    "            \"Quasi fatto... l'oro comico non si estrae da solo\",\n",
    "            \"Aspetta, sono pi\u00f9 divertente di quanto questa pausa suggerisca\",\n",
    "            \"Elaborazione... questa battuta far\u00e0 meglio essere buona\",\n",
    "            \"Il mio senso dell'umorismo ha bisogno di un momento...\",\n",
    "            \"Caricamento battuta... a differenza della mia vita amorosa, questo si completer\u00e0\",\n",
    "            \"Non sto procrastinando, sto creando suspense...\",\n",
    "            \"Roma non fu costruita in un giorno, e nemmeno l'oro comico\",\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Haal huidige taalconfiguratie op / Get current language configuration\n",
    "current_lang = LANGUAGE_CONFIG[LANGUAGE]\n",
    "print(f\"\ud83c\udf0d Taal / Sprache: {current_lang['name']}\")\n",
    "print(f\"\ud83d\udcda spaCy model: {current_lang['spacy_model']}\")\n",
    "print(f\"\ud83c\udfa4 Speech recognition: {current_lang['speech_recognition']}\")\n",
    "print(f\"\ud83d\udd0a TTS language: {current_lang['tts_lang']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ca6e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Agent Classes: Core Comedy Generation and Memory Systems\n",
    "# ============================================================================\n",
    "\n",
    "class LLMJokerAgent(ABC):\n",
    "    \"\"\"\n",
    "    Abstract base class for LLM-powered joke generation agents.\n",
    "    \n",
    "    This class provides a framework for generating jokes using Large Language Models\n",
    "    with different personalities. It handles profile loading, response generation,\n",
    "    and conversation memory management.\n",
    "    \n",
    "    Attributes:\n",
    "        MEMORY_SYSTEM_INSTRUCTION (str): System prompt for memory summarization\n",
    "        prompts_dir (Path): Directory containing personality profile markdown files\n",
    "        memory (str): Conversation summary maintained across interactions\n",
    "        output_format (str): XML format specification for joke responses\n",
    "        profiles (dict): Dictionary mapping profile names to their prompt content\n",
    "        profile_names (list): List of available personality profile names\n",
    "    \"\"\"\n",
    "\n",
    "    MEMORY_SYSTEM_INSTRUCTION = (\n",
    "        \"You are an advanced agent memory manager that keeps track of conversation \"\n",
    "        \"content by maintaining a SHORT summary. You transform the old summary, \"\n",
    "        \"with the new user message and agent response to the new summary.\"\n",
    "    )\n",
    "\n",
    "    def __init__(self, prompts_dir: Path):\n",
    "        \"\"\"\n",
    "        Initialize the joker agent and load personality profiles.\n",
    "        \n",
    "        Args:\n",
    "            prompts_dir: Path to directory containing personality .md files\n",
    "                        and output-format.md specification\n",
    "        \"\"\"\n",
    "        self.prompts_dir = Path(prompts_dir)\n",
    "        self.memory = \"\"\n",
    "\n",
    "        # Load output format specification\n",
    "        output_format_path = self.prompts_dir / \"output-format.md\"\n",
    "        with open(output_format_path, 'r') as f:\n",
    "            self.output_format = f.read()\n",
    "\n",
    "        # Load all personality profiles from markdown files\n",
    "        self.profiles = {}\n",
    "        for file in self.prompts_dir.iterdir():\n",
    "            if file.suffix == '.md' and 'output' not in file.name:\n",
    "                with open(file, 'r') as f:\n",
    "                    self.profiles[file.stem] = f.read()\n",
    "\n",
    "        self.profile_names = list(self.profiles.keys())\n",
    "\n",
    "    @abstractmethod\n",
    "    def _call_llm(self, system_instruction: str, user_content: str) -> str | None:\n",
    "        \"\"\"\n",
    "        Abstract method for LLM invocation. Subclasses implement this.\n",
    "        \n",
    "        Args:\n",
    "            system_instruction: The system prompt defining agent behavior\n",
    "            user_content: The user's input message\n",
    "            \n",
    "        Returns:\n",
    "            The LLM's text response, or None if the call fails\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def get_random_profile(self):\n",
    "        \"\"\"\n",
    "        Select a random personality profile from available profiles.\n",
    "        \n",
    "        Returns:\n",
    "            Tuple of (profile_name: str, profile_content: str)\n",
    "        \"\"\"\n",
    "        name = np.random.choice(self.profile_names)\n",
    "        return name, self.profiles[name]\n",
    "\n",
    "    def generate_response(\n",
    "        self, \n",
    "        user_response: str = \"I don't have much to say.\", \n",
    "        personality: str | None = None, \n",
    "        update_memory: bool = True, \n",
    "        N: int = 3, \n",
    "        example_joke: str | None = None\n",
    "    ) -> list[str]:\n",
    "        \"\"\"\n",
    "        Generate joke responses based on user input and selected personality.\n",
    "        \n",
    "        This method:\n",
    "        1. Selects or uses specified personality profile\n",
    "        2. Constructs system instruction with output format\n",
    "        3. Calls LLM with user input and optional example\n",
    "        4. Parses XML response into list of jokes\n",
    "        5. Optionally updates conversation memory\n",
    "        \n",
    "        Args:\n",
    "            user_response: The user's input text (default: generic response)\n",
    "            personality: Specific personality to use (None = random selection)\n",
    "            update_memory: Whether to update conversation memory after generation\n",
    "            N: Number of joke variations to generate\n",
    "            example_joke: Optional example of user's preferred joke style\n",
    "            \n",
    "        Returns:\n",
    "            List of joke strings. Returns fallback messages on error.\n",
    "        \"\"\"\n",
    "        # Select personality profile (random or specified)\n",
    "        _, profile = self.get_random_profile()\n",
    "        if personality is not None:\n",
    "            profile = self.profiles.get(personality, profile)\n",
    "\n",
    "        # Construct system instruction with formatted output specification\n",
    "        system_instruction = f\"{profile}\\n{self.output_format.replace('[N]', str(N))}\"\n",
    "\n",
    "        # Build prompt with optional example joke\n",
    "        prompt = user_response\n",
    "        if example_joke:\n",
    "            prompt = (\n",
    "                f\"{user_response}\\n\\n\"\n",
    "                f\"<example_of_joke_user_liked>{example_joke}</example_of_joke_user_liked>\"\n",
    "            )\n",
    "\n",
    "        # Call LLM\n",
    "        model_response = self._call_llm(system_instruction, prompt)\n",
    "        \n",
    "        if not model_response:\n",
    "            return [\"I'm done for the day\"]\n",
    "\n",
    "        # Strip markdown code fences if present (e.g., ```xml ... ```)\n",
    "        model_response = model_response.strip()\n",
    "        if model_response.startswith(\"```\"):\n",
    "            lines = model_response.split(\"\\n\")\n",
    "            lines = [l for l in lines[1:] if l.strip() != \"```\"]\n",
    "            model_response = \"\\n\".join(lines)\n",
    "\n",
    "        # Parse XML response to extract jokes\n",
    "        try:\n",
    "            parsed_response = ET.fromstring(model_response)\n",
    "            response_jokes = list(map(lambda x: x.text, parsed_response.findall(\"joke\")))\n",
    "            if response_jokes is None or response_jokes[0] is None:\n",
    "                return [\"I'm not feeling so funny today.\"]\n",
    "            if update_memory:\n",
    "                self.update_memory(user_response, response_jokes[0])\n",
    "        except Exception as e:\n",
    "            print(\"Actual model response: \", model_response)\n",
    "            return [\"I lost my train of thought. Could you repeat that?\"]\n",
    "\n",
    "        return response_jokes\n",
    "\n",
    "    def update_memory(self, user_response: str, model_response: str) -> str:\n",
    "        \"\"\"\n",
    "        Update conversation memory with a concise summary of the exchange.\n",
    "        \n",
    "        Uses the LLM to generate a summary that captures key information\n",
    "        from the conversation history, new user input, and agent response.\n",
    "        \n",
    "        Args:\n",
    "            user_response: The user's most recent message\n",
    "            model_response: The agent's most recent response\n",
    "            \n",
    "        Returns:\n",
    "            Updated memory summary string\n",
    "        \"\"\"\n",
    "        prompt = (\n",
    "            f\"previous summary: {self.memory}, \"\n",
    "            f\"new user msg: {user_response}, \"\n",
    "            f\"new system msg: {model_response}\"\n",
    "        )\n",
    "\n",
    "        summary = self._call_llm(self.MEMORY_SYSTEM_INSTRUCTION, prompt)\n",
    "\n",
    "        if summary:\n",
    "            self.memory = summary\n",
    "            print(\"New memory:\\n\", self.memory)\n",
    "\n",
    "        return self.memory\n",
    "\n",
    "\n",
    "class LLMAPIJokerAgent(LLMJokerAgent):\n",
    "    \"\"\"\n",
    "    Joker agent implementation using the Google Gemini API.\n",
    "    \n",
    "    This implementation communicates with Google's Gemini models via the\n",
    "    official Python SDK for reliable, production-ready joke generation.\n",
    "    \n",
    "    Attributes:\n",
    "        client: Google GenAI API client instance\n",
    "        model: Name of the Gemini model to use\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        prompts_dir: Path, \n",
    "        api_key: str | None = None, \n",
    "        model: str = \"gemini-2.5-flash\"\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize API-based joker agent with Google Gemini.\n",
    "        \n",
    "        Args:\n",
    "            prompts_dir: Path to personality profile directory\n",
    "            api_key: Google Cloud API key for Gemini access (reads from GEMINI_API_KEY env var if not provided)\n",
    "            model: Gemini model identifier (default: gemini-2.5-flash)\n",
    "        \"\"\"\n",
    "        super().__init__(prompts_dir)\n",
    "        \n",
    "        # Get API key from parameter or environment variable\n",
    "        if api_key is None:\n",
    "            api_key = os.environ.get('GEMINI_API_KEY')\n",
    "            if not api_key:\n",
    "                raise ValueError(\n",
    "                    \"No API key provided. Either pass api_key parameter or set GEMINI_API_KEY environment variable.\\n\"\n",
    "                    \"Get a new key at: https://aistudio.google.com/apikey\"\n",
    "                )\n",
    "        \n",
    "        self.client = genai.Client(api_key=api_key)\n",
    "        self.model = model\n",
    "\n",
    "    def _call_llm(self, system_instruction: str, user_content: str) -> str | None:\n",
    "        \"\"\"\n",
    "        Call Gemini API to generate content.\n",
    "        \n",
    "        Args:\n",
    "            system_instruction: System prompt defining agent behavior\n",
    "            user_content: User's input message\n",
    "            \n",
    "        Returns:\n",
    "            Generated text response, or None on failure\n",
    "        \"\"\"\n",
    "        response = self.client.models.generate_content(\n",
    "            model=self.model,\n",
    "            config=types.GenerateContentConfig(\n",
    "                system_instruction=system_instruction\n",
    "            ),\n",
    "            contents=user_content,\n",
    "        )\n",
    "        return response.text\n",
    "\n",
    "\n",
    "class LLMCLIJokerAgent(LLMJokerAgent):\n",
    "    \"\"\"\n",
    "    Joker agent implementation using the Gemini command-line interface.\n",
    "    \n",
    "    This implementation invokes the `gemini` CLI tool via subprocess,\n",
    "    useful for testing or environments where direct API access is limited.\n",
    "    \n",
    "    Note: Requires the `gemini` CLI tool to be installed and accessible in PATH.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, prompts_dir: Path):\n",
    "        \"\"\"\n",
    "        Initialize CLI-based joker agent.\n",
    "        \n",
    "        Args:\n",
    "            prompts_dir: Path to personality profile directory\n",
    "        \"\"\"\n",
    "        super().__init__(prompts_dir)\n",
    "\n",
    "    def _call_llm(self, system_instruction: str, user_content: str) -> str | None:\n",
    "        \"\"\"\n",
    "        Call Gemini via command-line interface.\n",
    "        \n",
    "        Executes the `gemini` CLI tool with a 60-second timeout and\n",
    "        captures the response from stdout.\n",
    "        \n",
    "        Args:\n",
    "            system_instruction: System prompt defining agent behavior\n",
    "            user_content: User's input message\n",
    "            \n",
    "        Returns:\n",
    "            Generated text response, or None on failure/timeout\n",
    "        \"\"\"\n",
    "        try:\n",
    "            result = subprocess.run(\n",
    "                [\"gemini\", \"-p\", f\"{system_instruction}\\n\\nUser: {user_content}\"],\n",
    "                capture_output=True,\n",
    "                text=True,\n",
    "                timeout=60\n",
    "            )\n",
    "\n",
    "            if result.returncode != 0:\n",
    "                print(f\"CLI Error: {result.stderr}\")\n",
    "                return None\n",
    "\n",
    "            return result.stdout.strip() or None\n",
    "\n",
    "        except subprocess.TimeoutExpired:\n",
    "            print(\"CLI timeout\")\n",
    "            return None\n",
    "        except FileNotFoundError:\n",
    "            print(\"Gemini CLI not found.\")\n",
    "            return None\n",
    "\n",
    "\n",
    "class MemoryAgent:\n",
    "    \"\"\"\n",
    "    Linguistic memory system for tracking conversation context.\n",
    "    \n",
    "    This agent extracts and maintains semantic features from user messages,\n",
    "    including subjects, objects, entities, verbs, and adjectives. It uses\n",
    "    pronoun resolution to link references across messages and generates\n",
    "    summaries that include both relevant and contrasting context.\n",
    "    \n",
    "    The memory system helps the joke agent understand conversation flow\n",
    "    and generate contextually appropriate humor.\n",
    "    \n",
    "    Attributes:\n",
    "        PRONOUNS: Set of common pronouns for reference resolution\n",
    "        memory: List of extracted feature dictionaries\n",
    "        max_memory_length: Maximum number of messages to retain\n",
    "    \"\"\"\n",
    "    \n",
    "    PRONOUNS = {\n",
    "        \"it\", \"they\", \"he\", \"she\", \"this\", \"that\", \"these\", \"those\", \n",
    "        \"i\", \"me\", \"my\", \"we\", \"us\", \"our\", \"you\", \"your\"\n",
    "    }\n",
    "\n",
    "    def __init__(self, max_memory_length: int):\n",
    "        \"\"\"\n",
    "        Initialize the memory agent.\n",
    "        \n",
    "        Args:\n",
    "            max_memory_length: Maximum number of conversation turns to remember\n",
    "        \"\"\"\n",
    "        self.memory = []\n",
    "        self.max_memory_length = max_memory_length\n",
    "        \n",
    "    def user_update(self, content: str):\n",
    "        \"\"\"\n",
    "        Process and store linguistic features from user input.\n",
    "        \n",
    "        Extracts entities, subjects, objects, verbs, and adjectives using\n",
    "        spaCy NLP. If pronouns are detected in subjects, resolves them\n",
    "        against the previous message's references.\n",
    "        \n",
    "        Args:\n",
    "            content: User's message text to process and store\n",
    "        \"\"\"\n",
    "        features = self._extract_features(content)\n",
    "        \n",
    "        # Pronoun resolution: link pronouns to previous message references\n",
    "        if self.memory and any(s.lower() in self.PRONOUNS for s in features[\"subj\"]):\n",
    "            prev = self.memory[-1]\n",
    "            features[\"resolved_refs\"] = (\n",
    "                prev.get(\"subj\", []) + \n",
    "                prev.get(\"obj\", []) + \n",
    "                prev.get(\"entities\", [])\n",
    "            )\n",
    "        \n",
    "        self.memory.append(features)\n",
    "        \n",
    "        # Maintain sliding window of recent messages\n",
    "        if len(self.memory) > self.max_memory_length:\n",
    "            self.memory = self.memory[-self.max_memory_length:]        \n",
    "\n",
    "    def get_full_memory_summary(self, n_contrast: int = 1) -> str:\n",
    "        \"\"\"\n",
    "        Generate a comprehensive memory summary with relevant and contrasting context.\n",
    "        \n",
    "        Creates a summary that includes:\n",
    "        1. Recent relevant messages (connected by shared references)\n",
    "        2. Contrasting context groups (unrelated conversation threads)\n",
    "        \n",
    "        This provides the joke agent with rich context while highlighting\n",
    "        topic shifts that might be good fodder for humor.\n",
    "        \n",
    "        Args:\n",
    "            n_contrast: Number of contrasting context groups to include\n",
    "            \n",
    "        Returns:\n",
    "            Summary string with relevant and contrasting contexts separated by \" | \"\n",
    "        \"\"\"\n",
    "        if not self.memory:\n",
    "            return \"\"\n",
    "\n",
    "        # Find messages relevant to the most recent message\n",
    "        current_idx = len(self.memory) - 1\n",
    "        relevant_idx = self._get_relevant_indices(current_idx)\n",
    "        non_relevant_idx = [i for i in range(current_idx + 1) if i not in relevant_idx]\n",
    "\n",
    "        # Group non-relevant messages into contrast clusters\n",
    "        contrast_groups = []\n",
    "        used = set()\n",
    "        for idx in sorted(non_relevant_idx, reverse=True):\n",
    "            if idx in used:\n",
    "                continue\n",
    "            group = [i for i in self._get_relevant_indices(idx) if i in non_relevant_idx]\n",
    "            if group:\n",
    "                contrast_groups.append(group)\n",
    "                used.update(group)\n",
    "\n",
    "        # Sample contrast groups for inclusion\n",
    "        selected_contrasts = random.sample(\n",
    "            contrast_groups, \n",
    "            min(n_contrast, len(contrast_groups))\n",
    "        )\n",
    "\n",
    "        # Build summary parts\n",
    "        parts = [self._summarize([self.memory[i] for i in relevant_idx])]\n",
    "        for group in selected_contrasts:\n",
    "            parts.append(self._summarize([self.memory[i] for i in group]))\n",
    "\n",
    "        return \" | \".join(filter(None, parts))\n",
    "\n",
    "    def _get_relevant_indices(self, target_idx: int) -> set[int]:\n",
    "        \"\"\"\n",
    "        Find all memory indices relevant to the target message.\n",
    "        \n",
    "        Messages are considered relevant if they share non-pronoun\n",
    "        references (entities, subjects, objects) with the target.\n",
    "        \n",
    "        Args:\n",
    "            target_idx: Index of the target message in memory\n",
    "            \n",
    "        Returns:\n",
    "            Set of indices for relevant messages (including target)\n",
    "        \"\"\"\n",
    "        if target_idx < 0 or target_idx >= len(self.memory):\n",
    "            return set()\n",
    "        target_refs = self._get_refs(self.memory[target_idx])\n",
    "        return {\n",
    "            i for i in range(target_idx + 1) \n",
    "            if not target_refs.isdisjoint(self._get_refs(self.memory[i]))\n",
    "        }\n",
    "\n",
    "    def _get_refs(self, f: dict) -> set:\n",
    "        \"\"\"\n",
    "        Extract all non-pronoun references from a feature dictionary.\n",
    "        \n",
    "        Args:\n",
    "            f: Feature dictionary with subj, obj, entities, resolved_refs\n",
    "            \n",
    "        Returns:\n",
    "            Set of reference strings (excluding pronouns)\n",
    "        \"\"\"\n",
    "        all_refs = (\n",
    "            f.get(\"subj\", []) + \n",
    "            f.get(\"obj\", []) + \n",
    "            f.get(\"entities\", []) + \n",
    "            f.get(\"resolved_refs\", [])\n",
    "        )\n",
    "        return {r for r in all_refs if r.lower() not in self.PRONOUNS}\n",
    "\n",
    "    def _summarize(self, memory_list: list[dict]) -> str:\n",
    "        \"\"\"\n",
    "        Create a compact text summary from a list of memory features.\n",
    "        \n",
    "        Combines linguistic features across messages into a single\n",
    "        space-separated string, filtering out pronouns.\n",
    "        \n",
    "        Args:\n",
    "            memory_list: List of feature dictionaries to summarize\n",
    "            \n",
    "        Returns:\n",
    "            Compact summary string\n",
    "        \"\"\"\n",
    "        if not memory_list:\n",
    "            return \"\"\n",
    "        \n",
    "        tuples = []\n",
    "        for f in memory_list:\n",
    "            tuples.append((\n",
    "                \" \".join(w for w in f.get(\"subj\", []) if w.lower() not in self.PRONOUNS),\n",
    "                \" \".join(f.get(\"verbs\", [])),\n",
    "                \" \".join(f.get(\"adjectives\", [])),\n",
    "                \" \".join(w for w in f.get(\"obj\", []) if w.lower() not in self.PRONOUNS),\n",
    "                \" \".join(f.get(\"entities\", [])),\n",
    "            ))\n",
    "        \n",
    "        return \" \".join(filter(None, (\" \".join(filter(None, t)) for t in zip(*tuples))))\n",
    "\n",
    "    def _extract_features(self, sentence: str) -> dict:\n",
    "        \"\"\"\n",
    "        Extract linguistic features from a sentence using spaCy.\n",
    "        \n",
    "        Features extracted:\n",
    "        - entities: Named entities (people, places, organizations, etc.)\n",
    "        - subj: Subject tokens (nsubj, nsubjpass dependencies)\n",
    "        - obj: Object tokens (dobj, pobj, iobj dependencies)\n",
    "        - adjectives: Adjective tokens\n",
    "        - verbs: Verb lemmas (base forms)\n",
    "        - past_tense: Boolean indicating past tense usage\n",
    "        - negated: Boolean indicating negation presence\n",
    "        - numbers: Numeric expressions\n",
    "        \n",
    "        Args:\n",
    "            sentence: Input text to analyze\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary of extracted features\n",
    "        \"\"\"\n",
    "        doc = nlp(sentence)\n",
    "        return {\n",
    "            \"entities\": [e.text for e in doc.ents],\n",
    "            \"subj\": [t.text for t in doc if \"subj\" in t.dep_],\n",
    "            \"obj\": [t.text for t in doc if \"obj\" in t.dep_],\n",
    "            \"adjectives\": [t.text for t in doc if t.pos_ == \"ADJ\"],\n",
    "            \"verbs\": [t.lemma_ for t in doc if t.pos_ == \"VERB\"],\n",
    "            \"past_tense\": any(t.tag_ == \"VBD\" for t in doc),\n",
    "            \"negated\": any(t.dep_ == \"neg\" for t in doc),\n",
    "            \"numbers\": [t.text for t in doc if t.like_num],\n",
    "        }\n",
    "\n",
    "\n",
    "class UserFeedbackTrackerAgent:\n",
    "    \"\"\"\n",
    "    Agent for tracking user feedback on jokes by personality type.\n",
    "    \n",
    "    This agent implements a simple feedback collection system that stores\n",
    "    positive and negative reactions to jokes, organized by personality.\n",
    "    The feedback is used by the UCB (Upper Confidence Bound) algorithm\n",
    "    to optimize personality selection over time.\n",
    "    \n",
    "    Attributes:\n",
    "        positive_feedbacks: Dict mapping personalities to liked jokes\n",
    "        negative_feedbacks: Dict mapping personalities to disliked jokes\n",
    "        awaiting_feedback: Tuple of (personality, joke) pending user reaction\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"Initialize the feedback tracker with empty feedback collections.\"\"\"\n",
    "        self.positive_feedbacks = defaultdict(list)\n",
    "        self.negative_feedbacks = defaultdict(list)\n",
    "        self.awaiting_feedback = None\n",
    "        \n",
    "    def await_feedback(self, joke: str, personality: str):\n",
    "        \"\"\"\n",
    "        Register a joke awaiting user feedback.\n",
    "        \n",
    "        Should be called immediately after presenting a joke to the user.\n",
    "        \n",
    "        Args:\n",
    "            joke: The joke text that was presented\n",
    "            personality: The personality profile that generated the joke\n",
    "        \"\"\"\n",
    "        self.awaiting_feedback = (personality, joke)\n",
    "        \n",
    "    def process_feedback(self, polarity: bool):\n",
    "        \"\"\"\n",
    "        Record user feedback for the awaiting joke.\n",
    "        \n",
    "        Adds the joke to either positive or negative feedback lists\n",
    "        based on the user's reaction.\n",
    "        \n",
    "        Args:\n",
    "            polarity: True for positive feedback (like), False for negative (dislike)\n",
    "        \"\"\"\n",
    "        if self.awaiting_feedback is None:\n",
    "            return\n",
    "        \n",
    "        feedbacks = self.positive_feedbacks if polarity else self.negative_feedbacks\n",
    "        feedbacks[self.awaiting_feedback[0]].append(self.awaiting_feedback[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5a14be",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Agent Initialization (Multi-Language)\n",
    "# ============================================================================\n",
    "\n",
    "# Load spaCy model based on configured language\n",
    "nlp = spacy.load(current_lang['spacy_model'])\n",
    "print(f\"\u2713 Loaded spaCy model: {current_lang['spacy_model']}\")\n",
    "\n",
    "# Initialize CLI-based joker agent (uses gemini command-line tool)\n",
    "joker_agent_cli = LLMCLIJokerAgent(os.getcwd()/Path(\"prompts\"))\n",
    "\n",
    "# Initialize API-based joker agent (uses Google Gemini API)\n",
    "joker_agent = LLMAPIJokerAgent(os.getcwd()/Path(\"prompts\"))\n",
    "\n",
    "# Initialize memory agent with 10-message sliding window\n",
    "memory = MemoryAgent(10)\n",
    "\n",
    "# Initialize feedback tracking agent\n",
    "feedback = UserFeedbackTrackerAgent()\n",
    "\n",
    "# Initialize speech recognition engine\n",
    "recognizer = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f569fa5",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center !important; max-width: 600px; margin: 0 auto;\">\n",
    "\n",
    "# JokeBloke\n",
    "\n",
    "**\ud83c\uddf3\ud83c\uddf1 Nederlands:**  \n",
    "Druk op `boot recorder` om hem wakker te maken. Druk vervolgens op `record` om tegen hem te praten. Als je klaar bent met praten, druk dan op `stop` en wacht geduldig op zijn reactie.\n",
    "\n",
    "**\ud83c\udde9\ud83c\uddea Deutsch:**  \n",
    "Dr\u00fccken Sie `boot recorder`, um ihn aufzuwecken. Dr\u00fccken Sie dann `record`, um mit ihm zu sprechen. Wenn Sie fertig sind, dr\u00fccken Sie `stop` und warten Sie geduldig auf seine Antwort.\n",
    "\n",
    "**\ud83c\uddec\ud83c\udde7 English (UK):**  \n",
    "Press `boot recorder` to wake him up. Then press `record` to talk to him. When you're done talking, press `stop` and wait patiently for his response.\n",
    "\n",
    "**\ud83c\uddee\ud83c\uddf9 Italiano:**  \n",
    "Premi `boot recorder` per svegliarlo. Poi premi `record` per parlargli. Quando hai finito di parlare, premi `stop` e aspetta pazientemente la sua risposta.\n",
    "\n",
    "---\n",
    "\n",
    "*Taal wijzigen / Sprache \u00e4ndern / Change language / Cambiare lingua: Pas de `LANGUAGE` variabele aan in cel 2 ('nl', 'de', 'en-gb', of 'it')*\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6675d7a8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35dec57552f54e7a8099667e78755a4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<style>\\n/* Center the layout and set a max-width */\\n.jp-Cell-outputArea {\\n    display: flex;\\n \u2026"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a09c93230931489c872fb1c157e31a34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "AudioRecorder()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88eb400f76cf4da38b0ebeb2e511c4cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(padding='5px'), outputs=({'output_type': 'stream', 'name': 'stdout', 'text': 'Recorder re\u2026"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93a81bc2b63a4deabc253268c40c06f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='Do you like this Answer?'), HTML(value='<img src=\"https://i.gifer.c\u2026"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Audio Processing and UI Helper Functions\n",
    "# ============================================================================\n",
    "\n",
    "def get_audio_as_wav_bytes(recorder):\n",
    "    \"\"\"\n",
    "    data = recorder.audiodata\n",
    "    srate = recorder.sampleRate\n",
    "    \n",
    "    if data is None or len(data) == 0:\n",
    "        raise ValueError(\"No audio recorded!\")\n",
    "\n",
    "    # Convert float32 audio to int16 format for WAV\n",
    "    data_int16 = (data * 32767).astype(np.int16)\n",
    "\n",
    "    # Create WAV file in memory\n",
    "    wav_bytes = BytesIO()\n",
    "    with wave.open(wav_bytes, 'wb') as wf:\n",
    "        wf.setnchannels(1)  # Mono audio\n",
    "        wf.setsampwidth(2)  # 16-bit samples\n",
    "        wf.setframerate(srate)\n",
    "        wf.writeframes(data_int16.tobytes())\n",
    "    wav_bytes.seek(0)\n",
    "    return wav_bytes\n",
    "\n",
    "\n",
    "def transcribe(recorder):\n",
    "    \"\"\"\n",
    "    Transcribe recorded audio to text using Google Speech Recognition.\n",
    "    \n",
    "    Converts the recorder's audio to WAV format and sends it to Google's\n",
    "    speech recognition API for transcription.\n",
    "    \n",
    "    Args:\n",
    "        recorder: ipyaudio.AudioRecorder instance with recorded audio\n",
    "        \n",
    "    Returns:\n",
    "        str: Transcribed text, or None if recognition fails\n",
    "    \"\"\"\n",
    "    wav_bytes = get_audio_as_wav_bytes(recorder)\n",
    "\n",
    "    with sr.AudioFile(wav_bytes) as source:\n",
    "        audio = recognizer.record(source)\n",
    "    \n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio, language='nl-NL')\n",
    "        print(\"Transcriptie:\", text)\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Kon audio niet verstaan\")\n",
    "    except sr.RequestError as e:\n",
    "        print(f\"API fout: {e}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def speak_text(text, save_file=None):\n",
    "    \"\"\"\n",
    "    Convert text to speech and play it using Google TTS and pygame.\n",
    "    \n",
    "    Generates an MP3 file using Google Text-to-Speech, then plays it\n",
    "    through pygame's mixer. Optionally saves the MP3 file to disk.\n",
    "    In environments without audio devices (like containers), prints the text instead.\n",
    "    \n",
    "    Args:\n",
    "        text: The text to convert to speech and play\n",
    "        save_file: Optional path to save the MP3 file (e.g., \"output.mp3\")\n",
    "    \n",
    "    Returns:\n",
    "        str: Path to saved MP3 file if save_file is provided, None otherwise\n",
    "    \"\"\"\n",
    "    Convert text to speech and play it using Google TTS and pygame.\n",
    "    \n",
    "    Generates an MP3 file using Google Text-to-Speech, then plays it\n",
    "    through pygame's mixer. This function blocks until playback completes.\n",
    "    In environments without audio devices (like containers), prints the text instead.\n",
    "    \n",
    "    Args:\n",
    "        text: The text to convert to speech and play\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create MP3 file (temporary or saved)\n",
    "        if save_file:\n",
    "            mp3_path = save_file\n",
    "            gTTS(text, lang='en', tld='co.uk').save(mp3_path)\n",
    "        else:\n",
    "            with tempfile.NamedTemporaryFile(suffix='.mp3', delete=False) as f:\n",
    "                mp3_path = f.name\n",
    "                gTTS(text, lang='en', tld='co.uk').save(f.name)\n",
    "        \n",
    "        # Play the audio\n",
    "        # Configure SDL for headless environment\n",
    "        os.environ.setdefault(\"SDL_AUDIODRIVER\", \"dummy\")\n",
    "        pygame.mixer.init()\n",
    "        pygame.mixer.music.load(mp3_path)\n",
    "        pygame.mixer.music.play()\n",
    "            # Wait for playback to complete\n",
    "        while pygame.mixer.music.get_busy():\n",
    "            pygame.time.wait(100)\n",
    "        \n",
    "        return mp3_path if save_file else None\n",
    "    except Exception as e:\n",
    "        # No audio device available (common in containers/headless environments)\n",
    "        print(f\"\ud83d\udd0a JokeBloke says: {text}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Loading Messages for User Engagement During LLM Processing\n",
    "# ============================================================================\n",
    "\n",
    "LOADING_MESSAGES = [\n",
    "    \"Even geduld, ik werk eraan...\",\n",
    "    \"Komedie kost tijd, anders dan het geduld van mijn ex...\",\n",
    "    \"Nog aan het denken... in tegenstelling tot mijn comedycarri\u00e8re gaat dit ergens heen\",\n",
    "    \"Een momentje, genie aan het werk... of op z'n minst lichte entertainment\",\n",
    "    \"Humor aan het laden... even geduld alstublieft\",\n",
    "    \"Mijn schrijvers staken weer...\",\n",
    "    \"Buffer humor... heb je geprobeerd me uit en aan te zetten?\",\n",
    "    \"Raadpleeg mijn innerlijke clown...\",\n",
    "    \"De clou zit vast in het verkeer...\",\n",
    "    \"Bijna klaar... comedy goud groeit niet op bomen\",\n",
    "    \"Even volhouden, ik ben grappiger dan deze pauze doet vermoeden\",\n",
    "    \"Bezig met verwerken... deze grap kan maar beter goed zijn\",\n",
    "    \"Mijn humorbot heeft even nodig...\",\n",
    "    \"Grap aan het laden... in tegenstelling tot mijn liefdeleven komt dit wel af\",\n",
    "    \"Ik stel niet uit, ik bouw spanning op...\",\n",
    "    \"Rome is niet in \u00e9\u00e9n dag gebouwd, comedy goud ook niet\",\n",
    "]\n",
    "\n",
    "\n",
    "def generate_with_loading_messages(\n",
    "    generator_func, \n",
    "    on_message=None, \n",
    "    min_delay: float = 2.0, \n",
    "    max_delay: float = 5.0\n",
    "):\n",
    "    \"\"\"\n",
    "    Execute a long-running function while displaying rotating loading messages.\n",
    "    \n",
    "    Runs the generator function in a background thread and periodically calls\n",
    "    the on_message callback with humorous loading messages to keep the user\n",
    "    engaged during LLM processing.\n",
    "    \n",
    "    Args:\n",
    "        generator_func: Callable that performs the long-running operation\n",
    "        on_message: Optional callback function(message: str) for displaying messages\n",
    "        min_delay: Minimum seconds between loading messages\n",
    "        max_delay: Maximum seconds between loading messages\n",
    "        \n",
    "    Returns:\n",
    "        The return value from generator_func\n",
    "        \n",
    "    Raises:\n",
    "        Any exception raised by generator_func\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    error = []\n",
    "    done = threading.Event()\n",
    "\n",
    "    def background_task():\n",
    "        \"\"\"Execute the generator function and capture result or error.\"\"\"\n",
    "        try:\n",
    "            result.append(generator_func())\n",
    "            \n",
    "        return mp3_path if save_file else None\n",
    "        except Exception as e:\n",
    "            error.append(e)\n",
    "        finally:\n",
    "            done.set()\n",
    "\n",
    "    # Start background thread for generation\n",
    "    thread = threading.Thread(target=background_task, daemon=True)\n",
    "    thread.start()\n",
    "\n",
    "    # Display loading messages until generation completes\n",
    "    used_messages = []\n",
    "    while not done.is_set():\n",
    "        delay = random.uniform(min_delay, max_delay)\n",
    "        if done.wait(timeout=delay):\n",
    "            break\n",
    "        \n",
    "        # Pick a message we haven't used yet to avoid repetition\n",
    "        if len(used_messages) >= len(LOADING_MESSAGES):\n",
    "            used_messages = []\n",
    "        available = [m for m in LOADING_MESSAGES if m not in used_messages]\n",
    "        message = random.choice(available)\n",
    "        used_messages.append(message)\n",
    "        \n",
    "        if on_message:\n",
    "            on_message(message)\n",
    "\n",
    "    thread.join()\n",
    "\n",
    "    # Propagate any errors from the background thread\n",
    "    if error:\n",
    "        raise error[0]\n",
    "    return result[0]\n",
    "\n",
    "\n",
    "def save_wav_from_recorder(recorder, filename: str = \"recording.wav\"):\n",
    "    \"\"\"\n",
    "    Save recorded audio to a WAV file on disk.\n",
    "    \n",
    "    Utility function for debugging or archiving audio recordings.\n",
    "    \n",
    "    Args:\n",
    "        recorder: ipyaudio.AudioRecorder instance with recorded audio\n",
    "        filename: Output filename for the WAV file\n",
    "        \n",
    "    Returns:\n",
    "        str: The filename if successful, None if no audio to save\n",
    "    \"\"\"\n",
    "    data = recorder.audiodata\n",
    "    sr = recorder.sampleRate\n",
    "    \n",
    "    if data is None or len(data) == 0:\n",
    "        print(\"No audio data to save!\")\n",
    "        return None\n",
    "\n",
    "    # Convert to 16-bit PCM\n",
    "    data_int16 = (data * 32767).astype(np.int16)\n",
    "\n",
    "    with wave.open(filename, \"wb\") as f:\n",
    "        f.setnchannels(1)\n",
    "        f.setsampwidth(2)\n",
    "        f.setframerate(sr)\n",
    "        f.writeframes(data_int16.tobytes())\n",
    "\n",
    "    print(f\"Saved: {filename}\")\n",
    "    return filename\n",
    "\n",
    "\n",
    "def plot_audio(rec):\n",
    "    \"\"\"\n",
    "    Visualize the recorded audio waveform using matplotlib.\n",
    "    \n",
    "    Useful for debugging audio quality and verifying recordings.\n",
    "    \n",
    "    Args:\n",
    "        rec: ipyaudio.AudioRecorder instance with recorded audio\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.plot(rec.audiodata)\n",
    "    plt.title(\"Recorded Audio Waveform\")\n",
    "    plt.xlabel(\"Samples\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# UI Widget Setup\n",
    "# ============================================================================\n",
    "\n",
    "# Audio recorder widget\n",
    "rec = ipyaudio.AudioRecorder()\n",
    "\n",
    "# Status output for recorder state messages\n",
    "status_out = Output(layout={'padding': '5px'})\n",
    "\n",
    "# Feedback UI components\n",
    "text_label = widgets.Label(value=\"Vind je dit leuk?\")\n",
    "like_button = widgets.Button(description=\": )\", button_style='success')\n",
    "dislike_button = widgets.Button(description=\": (\", button_style='danger')\n",
    "\n",
    "# Loading indicator with animated GIF\n",
    "loading_indicator = widgets.HTML(\n",
    "    value='<img src=\"https://i.gifer.com/ZZ5H.gif\" width=\"30\" style=\"vertical-align:middle;\"> '\n",
    "          '<span>Bedenk iets grappigs...</span>'\n",
    ")\n",
    "loading_indicator.layout.display = 'none'\n",
    "\n",
    "# Output area for feedback messages\n",
    "output = widgets.Output()\n",
    "\n",
    "\n",
    "def set_loading_state(is_loading: bool):\n",
    "    \"\"\"\n",
    "    Enable or disable UI elements based on loading state.\n",
    "    \n",
    "    During joke generation:\n",
    "    - Disables feedback buttons to prevent premature clicks\n",
    "    - Makes the recorder appear disabled (CSS opacity/pointer-events)\n",
    "    - Shows loading indicator, hides feedback prompt\n",
    "    \n",
    "    Args:\n",
    "        is_loading: True to show loading state, False to show interactive state\n",
    "    \"\"\"\n",
    "    like_button.disabled = is_loading\n",
    "    dislike_button.disabled = is_loading\n",
    "    \n",
    "    # ipyaudioworklet doesn't have a disabled property, so we use CSS\n",
    "    if is_loading:\n",
    "        rec.layout.opacity = '0.5'\n",
    "        rec.layout.pointer_events = 'none'\n",
    "    else:\n",
    "        rec.layout.opacity = '1'\n",
    "        rec.layout.pointer_events = 'auto'\n",
    "    \n",
    "    loading_indicator.layout.display = 'inline' if is_loading else 'none'\n",
    "    text_label.layout.display = 'none' if is_loading else 'inline'\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Event Handlers\n",
    "# ============================================================================\n",
    "\n",
    "@status_out.capture(clear_output=True)\n",
    "def status_changed(change):\n",
    "    \"\"\"Display recorder status changes.\"\"\"\n",
    "    print(\"Status:\", change.new)\n",
    "\n",
    "\n",
    "@status_out.capture()\n",
    "def on_status_change(change):\n",
    "    \"\"\"\n",
    "    Main event handler for audio recorder status changes.\n",
    "    \n",
    "    Triggered when the user stops recording. This function orchestrates\n",
    "    the entire joke generation pipeline:\n",
    "    \n",
    "    1. Transcribe audio to text\n",
    "    2. Update conversation memory with user input\n",
    "    3. Select optimal personality using UCB algorithm\n",
    "    4. Generate joke(s) with loading messages\n",
    "    5. Speak the joke back to the user\n",
    "    6. Wait for user feedback\n",
    "    \n",
    "    The UCB (Upper Confidence Bound) algorithm balances exploration of new\n",
    "    personalities with exploitation of personalities that have received\n",
    "    positive feedback in the past.\n",
    "    \"\"\"\n",
    "    if change.new in (\"STOPPED\", \"RECORDED\"):\n",
    "        # Step 1: Transcribe user's voice input\n",
    "        user_input = transcribe(rec)\n",
    "        if not user_input:\n",
    "            return\n",
    "\n",
    "        # Step 2: Update conversation memory\n",
    "        memory.user_update(user_input)\n",
    "\n",
    "        personalities = joker_agent.profile_names\n",
    "\n",
    "        # Step 3: Select personality using UCB (Upper Confidence Bound) algorithm\n",
    "        # This balances exploration (trying untested personalities) with\n",
    "        # exploitation (using personalities that have received positive feedback)\n",
    "        \n",
    "        # Calculate total feedback count across all personalities\n",
    "        n_total = sum(\n",
    "            len(feedback.positive_feedbacks[pers]) + len(feedback.negative_feedbacks[pers])\n",
    "            for pers in personalities\n",
    "        )\n",
    "\n",
    "        ucb_scores = []\n",
    "        for pers in personalities:\n",
    "            positive = len(feedback.positive_feedbacks[pers])\n",
    "            negative = len(feedback.negative_feedbacks[pers])\n",
    "            n = positive + negative\n",
    "\n",
    "            if n == 0:\n",
    "                # Untested personalities get infinite UCB to encourage exploration\n",
    "                ucb_scores.append(float('inf'))\n",
    "            else:\n",
    "                # UCB score = mean success rate + exploration bonus\n",
    "                mean = positive / n\n",
    "                exploration_bonus = np.sqrt(2 * np.log(n_total + 1) / n)\n",
    "                ucb_scores.append(mean + exploration_bonus)\n",
    "\n",
    "        # Pick personality with highest UCB score (random tiebreak for infinite scores)\n",
    "        max_ucb = max(ucb_scores)\n",
    "        best_indices = [i for i, score in enumerate(ucb_scores) if score == max_ucb]\n",
    "        personality_pick = np.random.choice(best_indices)\n",
    "        personality = personalities[personality_pick]\n",
    "        \n",
    "        print(\"Persoonlijkheid:\", personality)\n",
    "\n",
    "        # Step 4: Get most recent liked joke for this personality as an example\n",
    "        liked_jokes = feedback.positive_feedbacks[personality]\n",
    "        example_joke = liked_jokes[-1] if liked_jokes else None\n",
    "\n",
    "        def update_loading_message(msg):\n",
    "            \"\"\"Callback to update the loading indicator with a new message.\"\"\"\n",
    "            loading_indicator.value = (\n",
    "                f'<img src=\"https://i.gifer.com/ZZ5H.gif\" width=\"30\" '\n",
    "                f'style=\"vertical-align:middle;\"> <span>{msg}</span>'\n",
    "            )\n",
    "\n",
    "        # Step 5: Generate joke with loading messages\n",
    "        set_loading_state(True)\n",
    "        try:\n",
    "            # Build prompt with conversation history and current input\n",
    "            prompt = f\"<history>{memory.get_full_memory_summary(2)}</history>\\n{user_input}\"\n",
    "            \n",
    "            jokes = generate_with_loading_messages(\n",
    "                lambda: joker_agent.generate_response(\n",
    "                    prompt, \n",
    "                    update_memory=False, \n",
    "                    personality=personality, \n",
    "                    N=1, \n",
    "                    example_joke=example_joke\n",
    "                ),\n",
    "                on_message=update_loading_message\n",
    "            )\n",
    "        finally:\n",
    "            set_loading_state(False)\n",
    "\n",
    "        print(\"Reactie:\", jokes[0])\n",
    "\n",
    "        # Step 6: Speak the joke and await feedback\n",
    "        speak_text(jokes[0])\n",
    "        feedback.await_feedback(jokes[0], personality)\n",
    "\n",
    "\n",
    "def on_like_clicked(b):\n",
    "    \"\"\"\n",
    "    Handle positive feedback (like button clicked).\n",
    "    \n",
    "    Records the positive feedback, speaks a thank you message,\n",
    "    and displays confirmation to the user.\n",
    "    \"\"\"\n",
    "    with output:\n",
    "        clear_output()\n",
    "        feedback.process_feedback(True)\n",
    "        speak_text(\"Dank je!\")\n",
    "        print(\"Je vond dit leuk!\")\n",
    "\n",
    "\n",
    "def on_dislike_clicked(b):\n",
    "    \"\"\"\n",
    "    Handle negative feedback (dislike button clicked).\n",
    "    \n",
    "    Records the negative feedback, speaks a self-deprecating response,\n",
    "    and displays confirmation to the user.\n",
    "    \"\"\"\n",
    "    with output:\n",
    "        clear_output()\n",
    "        feedback.process_feedback(False)\n",
    "        speak_text(\"Wow, lastig publiek!\")\n",
    "        print(\"Je vond dit niet leuk!\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Wire Event Handlers to Widgets\n",
    "# ============================================================================\n",
    "\n",
    "rec.observe(status_changed, \"status\")\n",
    "rec.observe(on_status_change, \"status\")\n",
    "like_button.on_click(on_like_clicked)\n",
    "dislike_button.on_click(on_dislike_clicked)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Display UI with Custom Styling\n",
    "# ============================================================================\n",
    "\n",
    "# Comprehensive CSS styling for the notebook interface\n",
    "STYLE_SHEET_CONTENT = \"\"\"\n",
    "/* Center the layout and set a max-width */\n",
    ".jp-Cell-outputArea {\n",
    "    display: flex;\n",
    "    flex-direction: column;\n",
    "    align-items: center;\n",
    "}\n",
    "\n",
    ".jp-OutputArea-child {\n",
    "    max-width: 600px;\n",
    "    width: 100%;\n",
    "    padding: 5px 0;\n",
    "    box-sizing: border-box;\n",
    "}\n",
    "\n",
    "/* Hide the audio player widget */\n",
    ".jupyter-widgets audio,\n",
    ".jupyter-widgets video {\n",
    "    display: none !important;\n",
    "}\n",
    "\n",
    "/* Style the buttons - auto height to fit content */\n",
    ".widget-button {\n",
    "    background-color: #f0f0f0;\n",
    "    border: 1px solid #ccc;\n",
    "    border-radius: 8px;\n",
    "    padding: 4px 12px;\n",
    "    margin: 5px;\n",
    "    font-size: 14px;\n",
    "    font-weight: bold;\n",
    "    cursor: pointer;\n",
    "    transition: background-color 0.3s, transform 0.1s;\n",
    "    box-sizing: border-box;\n",
    "    height: auto !important;\n",
    "    min-height: unset !important;\n",
    "    line-height: 1.4;\n",
    "}\n",
    "\n",
    ".widget-button:hover {\n",
    "    background-color: #e0e0e0;\n",
    "}\n",
    "\n",
    ".widget-button:active {\n",
    "    transform: scale(0.98);\n",
    "}\n",
    "\n",
    ".widget-button:disabled {\n",
    "    background-color: #f5f5f5;\n",
    "    color: #aaa;\n",
    "    cursor: not-allowed;\n",
    "}\n",
    "\n",
    ".widget-button.mod-success {\n",
    "    background-color: #28a745;\n",
    "    color: white;\n",
    "    border-color: #28a745;\n",
    "}\n",
    "\n",
    ".widget-button.mod-success:hover {\n",
    "    background-color: #218838;\n",
    "}\n",
    "\n",
    ".widget-button.mod-danger {\n",
    "    background-color: #dc3545;\n",
    "    color: white;\n",
    "    border-color: #dc3545;\n",
    "}\n",
    "\n",
    ".widget-button.mod-danger:hover {\n",
    "    background-color: #c82333;\n",
    "}\n",
    "\n",
    "/* Style the output text area - auto-grow with content */\n",
    ".widget-output {\n",
    "    width: 100%;\n",
    "    min-height: 50px;\n",
    "    max-height: none;\n",
    "    overflow: visible;\n",
    "}\n",
    "\n",
    ".lm-Widget {\n",
    "    text-align: center;\n",
    "}\n",
    "\n",
    ".widget-output .jp-RenderedText {\n",
    "    background-color: #f8f9fa;\n",
    "    border: 1px solid #dee2e6;\n",
    "    border-radius: 8px;\n",
    "    padding: 15px;\n",
    "    margin-top: 10px;\n",
    "    text-align: left;\n",
    "    min-height: 40px;\n",
    "    height: auto;\n",
    "}\n",
    "\n",
    ".widget-output .jp-RenderedText pre {\n",
    "    white-space: pre-wrap;\n",
    "    word-wrap: break-word;\n",
    "    font-family: monospace;\n",
    "    font-size: 14px;\n",
    "    margin: 0;\n",
    "}\n",
    "\n",
    "/* Style the text label */\n",
    ".widget-label {\n",
    "    font-weight: bold;\n",
    "    font-size: 16px;\n",
    "    text-align: center;\n",
    "}\n",
    "\n",
    "/* Style the loading indicator */\n",
    ".widget-html-content {\n",
    "    display: flex;\n",
    "    align-items: center;\n",
    "    gap: 8px;\n",
    "}\n",
    "\n",
    ".widget-html-content img {\n",
    "    width: 30px;\n",
    "    height: 30px;\n",
    "}\n",
    "\n",
    ".widget-html-content span {\n",
    "    font-style: italic;\n",
    "    color: #666;\n",
    "}\n",
    "\n",
    "/* Like/dislike buttons sizing - auto height */\n",
    ".widget-button.mod-success,\n",
    ".widget-button.mod-danger {\n",
    "    min-width: 70px;\n",
    "    font-size: 18px;\n",
    "    padding: 6px 16px;\n",
    "    height: auto !important;\n",
    "    min-height: unset !important;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Inject CSS into notebook\n",
    "display(widgets.HTML(f\"<style>{STYLE_SHEET_CONTENT}</style>\"))\n",
    "\n",
    "# Display initial status message\n",
    "status_out.append_stdout(\"Recorder klaar.\\n\")\n",
    "\n",
    "# Assemble and display the feedback UI\n",
    "feedback_ui = widgets.VBox([\n",
    "    widgets.HBox(\n",
    "        [text_label, loading_indicator], \n",
    "        layout=widgets.Layout(justify_content='center')\n",
    "    ),\n",
    "    widgets.HBox(\n",
    "        [like_button, dislike_button], \n",
    "        layout=widgets.Layout(justify_content='center')\n",
    "    ),\n",
    "    output\n",
    "], layout=widgets.Layout(align_items='center'))\n",
    "\n",
    "# Display all UI components\n",
    "display(rec)\n",
    "display(status_out)\n",
    "display(feedback_ui)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}